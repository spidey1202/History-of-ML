<!DOCTYPE html>
<html lang="en" >
<head>
	 <link rel="shortcut icon" href="reloj.png" type="image/x-icon">
    <link rel="icon" href="reloj.png" type="image/x-icon">
	
  <meta charset="UTF-8">
  <title>History of Machine Learning</title>
  <link rel="stylesheet" href="./style.css">
	 
</head>
<body>
	
<!-- partial:index.partial.html -->
<section class="intro">
  <div class="container">
    <h1>üíª History of Machine Learning  ü§≥</h1>
	  <h2>Evolution of machine learning through key milestones!</h2>
	  <h3>üë©‚Äçüíª By Sweta Singh</h3>
	  <h3>üè´ An undergraduate</h3>
	  <h3>‚úçÔ∏è Computer Science and Engineering Department</h3>
  </div>
</section>

<section class="timeline">
  <ul>
    <li>
      <div>
        <time>1943: McCulloch-Pitts neural model</time> Warren McCulloch and Walter Pitts propose a mathematical model of artificial neurons, laying the groundwork for neural networks.<br><center><img src="https://previews.123rf.com/images/sspopov/sspopov0805/sspopov080500045/3027645-electr%C3%B3nico-de-los-tubos-al-vac%C3%ADo-con-el-cuerpo-de-vidrio-de-los-diferentes-establecimiento.jpg" width="150" height="150"/></center>
      </div>
    </li>
    <li>
      <div>
        <time>1956: Dartmouth Workshop</time>  The Dartmouth Workshop marks the birth of AI as a field, with the aim of developing machines that can mimic human intelligence.

		<br><center><img src="https://curiosfera-historia.com/wp-content/uploads/qui%C3%A9n-invent%C3%B3-el-transistor-1.jpg" width="150" height="150"/></center>
      </div>
    </li>
    <li>
      <div>
        <time>1957: Perceptron</time> IFrank Rosenblatt develops the perceptron, a type of artificial neural network, capable of learning and pattern recognition.<br>
		  <center><img src="https://4.bp.blogspot.com/-aPFdahLefZM/VCNmU0v6p6I/AAAAAAAAAD0/Pb9e0C7DY-4/s1600/IBSYS.docx.jpg" width="150" height="150"/></center>
      </div>
    </li>
    <li>
      <div>
        <time>1967: Nearest Neighbor Algorithm</time> The Nearest Neighbor algorithm is introduced for pattern recognition and classification tasks.
		  <br><center><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/7d/IBM_704_mainframe.gif/300px-IBM_704_mainframe.gif" width="150" height="150"/></center>
      </div>
    </li>
    <li>
      <div>
        <time>1970: Decision Trees  </time> The concept of decision trees is proposed as a machine learning method for classification and regression.
		  <br><center><img src="https://3.bp.blogspot.com/-zhHQdX07UnA/V1S9HnEPQaI/AAAAAAAAAPs/-_z3ef1ItGY9GGAR9yCU9ENRnX35MuTQACLcB/w1200-h630-p-k-no-nu/rank-exec-2.jpg" width="150" height="150"/></center>
      </div>
    </li>
    <li>
      <div>
        <time>1980: Backpropagation</time> Paul Werbos introduces the backpropagation algorithm, a technique for training multi-layer neural networks.
		  <br><center><img src="https://i.pinimg.com/originals/e2/cd/68/e2cd68b45e523ee4671633dc370a12b6.gif" width="150" height="150"/></center>
      </div>
    </li>
    <li>
      <div>
        <time>1986: Support Vector Machines (SVM)</time>Vladimir Vapnik and colleagues develop Support Vector Machines, a powerful algorithm for classification and regression tasks.      </div>
    </li>
    <li>
      <div>
        <time>1995: Reinforcement Learning </time> Reinforcement learning algorithms, such as Q-learning and TD-Gammon, gain popularity for training agents in an interactive environment.
		   </div>
    </li>
    <li>
    
    </ul>
  </section>
    <footer>
    <h5 align="left">Bibliography/links</h5>
      <ol type=‚ÄùA‚Äù>
    <li align="left">
   </li>
    </ol>
      
  </footer>
  <!-- partial -->
    <script  src="./script.js"></script>
  
  </body>
  </html>
  
