<!DOCTYPE html>
<html lang="en" >
<head>
	 <link rel="shortcut icon" href="reloj.png" type="image/x-icon">
    <link rel="icon" href="reloj.png" type="image/x-icon">
	
  <meta charset="UTF-8">
  <title>History of Machine Learning</title>
  <link rel="stylesheet" href="./style.css">
	 
</head>
<body>
	
<!-- partial:index.partial.html -->
<section class="intro">
  <div class="container">
    <h1>üíª History of Machine Learning  ü§≥</h1>
	  <h2>Evolution of machine learning through key milestones!</h2>
	  <h3>üë©‚Äçüíª By Sweta Singh</h3>
	  <h3>üè´ An undergraduate</h3>
	  <h3>‚úçÔ∏è Computer Science and Engineering Department</h3>
  </div>
</section>

<section class="timeline">
  <ul>
    <li>
      <div>
        <time>1943: McCulloch-Pitts neural model</time> Warren McCulloch and Walter Pitts propose a mathematical model of artificial neurons, laying the groundwork for neural networks.<br><center><img src="https://previews.123rf.com/images/sspopov/sspopov0805/sspopov080500045/3027645-electr%C3%B3nico-de-los-tubos-al-vac%C3%ADo-con-el-cuerpo-de-vidrio-de-los-diferentes-establecimiento.jpg" width="150" height="150"/></center>
      </div>
    </li>
    <li>
      <div>
        <time>1956: Dartmouth Workshop</time>  The Dartmouth Workshop marks the birth of AI as a field, with the aim of developing machines that can mimic human intelligence.

		<br><center><img src="assets/img/1.png" width="150" height="150"/></center>
      </div>
    </li>
    <li>
      <div>
        <time>1957: Perceptron</time> IFrank Rosenblatt develops the perceptron, a type of artificial neural network, capable of learning and pattern recognition.<br>
		  <center><img src="https://4.bp.blogspot.com/-aPFdahLefZM/VCNmU0v6p6I/AAAAAAAAAD0/Pb9e0C7DY-4/s1600/IBSYS.docx.jpg" width="150" height="150"/></center>
      </div>
    </li>
    <li>
      <div>
        <time>1967: Nearest Neighbor Algorithm</time> The Nearest Neighbor algorithm is introduced for pattern recognition and classification tasks.
		  <br><center><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/7d/IBM_704_mainframe.gif/300px-IBM_704_mainframe.gif" width="150" height="150"/></center>
      </div>
    </li>
    <li>
      <div>
        <time>1970: Decision Trees  </time> The concept of decision trees is proposed as a machine learning method for classification and regression.
		  <br><center><img src="https://3.bp.blogspot.com/-zhHQdX07UnA/V1S9HnEPQaI/AAAAAAAAAPs/-_z3ef1ItGY9GGAR9yCU9ENRnX35MuTQACLcB/w1200-h630-p-k-no-nu/rank-exec-2.jpg" width="150" height="150"/></center>
      </div>
    </li>
    <li>
      <div>
        <time>1980: Backpropagation</time> Paul Werbos introduces the backpropagation algorithm, a technique for training multi-layer neural networks.
		  <br><center><img src="https://i.pinimg.com/originals/e2/cd/68/e2cd68b45e523ee4671633dc370a12b6.gif" width="150" height="150"/></center>
      </div>
    </li>
    <li>
      <div>
        <time>1986: Support Vector Machines (SVM)</time>Vladimir Vapnik and colleagues develop Support Vector Machines, a powerful algorithm for classification and regression tasks.      </div>
    </li>
    <li>
      <div>
        <time>1995: Reinforcement Learning </time> Reinforcement learning algorithms, such as Q-learning and TD-Gammon, gain popularity for training agents in an interactive environment.
		   </div>
    </li>
    <li>
    <div>
      <time>1997: Deep Blue vs. Garry Kasparov</time> IBM's Deep Blue defeats chess world champion Garry Kasparov, demonstrating the potential of AI in complex strategic games.
      </div>
    </li>
    <li>
      <div>
        <time>2006: Deep Learning Revival</time> Geoff Hinton and colleagues show the effectiveness of deep neural networks in training large-scale models using unsupervised pre-training. 
      </div>
      </li>
      <li>
        <div>
          <time>2011: ImageNet Competition </time> The ImageNet Large Scale Visual Recognition Challenge is introduced, driving advancements in image classification using deep convolutional neural networks.
        </div>
        </li> 

      <li>
        <div>
          <time>2012: AlexNet </time> AlexNet, a deep convolutional neural network developed by Alex Krizhevsky and colleagues, achieves a significant breakthrough in image classification accuracy.
        </div>
        </li> 
        <li>
          <div>
              <time>2014: Generative Adversarial Networks (GANs) </time> TAlexNet, a deep convolutional neural network developed by Alex Krizhevsky and colleagues, achieves a significant breakthrough in image classification accuracy.
          </div>
          </li> 
        <li>
              <div>
                <time>2016: AlphaGo </time>DeepMind's AlphaGo defeats world champion Go player Lee Sedol, demonstrating the power of deep reinforcement learning in complex board games.
              </div>
            </li> 
        <li>
            <div>
                  <time>2017: Transfer Learning </time> Transfer learning techniques gain prominence, allowing pre-trained models to be utilized for various downstream tasks with limited data.
                </div>
            </li> 
        <li>
            <div>
                    <time>2018: Transformer Networks </time> The Transformer architecture is introduced, revolutionizing natural language processing with models like BERT and GPT.</div>
            </li> 

        <li>
              <div>
                      <time>2020: GPT-3 </time> OpenAI releases GPT-3, a large-scale language model that exhibits impressive text generation capabilities and marks a milestone in natural language processing.
              </div>
        </li> 

    </ul>
  </section>
    
  
  <footer>
    <h3 align="center">This timeline highlights some significant moments in the history of machine learning, showcasing breakthroughs in neural networks, reinforcement learning, deep learning, and other key areas. For further details, you can explore academic papers, research articles, and books dedicated to each specific breakthrough or topic. </h3>
      <ol align=" left">
        <li>Academic Papers:

          "A Logical Calculus of the Ideas Immanent in Nervous Activity" by Warren McCulloch and Walter Pitts (1943)
          
          Paper: https://journals.sagepub.com/doi/10.1177/002200947200700105
          Summary: Introduces the McCulloch-Pitts neural model, a foundational work in neural network theory.
          "The perceptron: A probabilistic model for information storage and organization in the brain" by Frank Rosenblatt (1957)
          
          Paper: https://psycnet.apa.org/record/1959-06940-001
          Summary: Describes the perceptron, an early neural network model capable of learning and pattern recognition.
          "Support-Vector Networks" by Vladimir Vapnik (1995)
          
          Paper: https://link.springer.com/article/10.1007/BF00994018
          Summary: Introduces Support Vector Machines (SVM), a popular algorithm for classification and regression tasks.
          "Playing Atari with Deep Reinforcement Learning" by Volodymyr Mnih et al. (2013)
          
          Paper: https://arxiv.org/abs/1312.5602
          Summary: Demonstrates the use of deep reinforcement learning in playing Atari games.
          Articles:
          
          "A Few Useful Things to Know About Machine Learning" by Pedro Domingos (2012)
        </li>
          
          <li>Article: https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf
          Summary: Provides insights and practical tips on various aspects of machine learning.
          "The Unreasonable Effectiveness of Deep Learning" by Yann LeCun, Yoshua Bengio, and Geoffrey Hinton (2015)
          
          Article: https://www.nature.com/articles/nature14539
          Summary: Discusses the remarkable impact of deep learning and its successes in various domains.
          Books:
          
          "Deep Learning" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville (2016)
          </li>
          <li>
          Book: http://www.deeplearningbook.org/
          Summary: Offers a comprehensive introduction to deep learning, covering various topics and techniques.
          "Pattern Recognition and Machine Learning" by Christopher M. Bishop (2006)
          
          Book: https://www.microsoft.com/en-us/research/people/cmbishop/prml-book/
          Summary: Provides a comprehensive overview of pattern recognition and machine learning algorithms.
          "Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow" by Aur√©lien G√©ron (2019)
          
          Book: https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/
          Summary: Offers practical guidance and code examples for machine learning using popular libraries.
          </li>        
      </ol>
  </footer>
  <!-- partial -->
    <script  src="./script.js"></script>
  
  </body>
  </html>
  
